{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"fastrepl==0.0.8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find all releases [here](https://pypi.org/project/fastrepl).\n",
    "\n",
    "## Setup FastREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using it in a script\n",
    "import fastrepl\n",
    "\n",
    "# When using it in a notebook\n",
    "import fastrepl.repl as fastrepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "We will use [daily_dialog](https://huggingface.co/datasets/daily_dialog) from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sample'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"daily_dialog\", split=\"test\")\n",
    "ds = ds.shuffle(4)\n",
    "ds = ds.select(range(50))\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub(r\"\\s+([,.'!?])\", r\"\\1\", text.strip())\n",
    "\n",
    "\n",
    "def get_input(row):\n",
    "    msgs = [clean(msg) for msg in row[\"dialog\"]]\n",
    "    row[\"sample\"] = \"\\n\".join(msgs)  # `SimpleEvaluator` expect `sample` column\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "ds = ds.map(get_input, remove_columns=[\"dialog\", \"act\", \"emotion\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluator\n",
    "\n",
    "Here, we are doing simple classifiction, but there are two interesting points.\n",
    "\n",
    "1. You can pass nearly any model for evaluation. (Thanks to [LiteLLM](https://github.com/BerriAI/litellm)).\n",
    "2. **`fastrepl` enhances accuracy by reducing [bias](/guides/dealing_with_bias.md)**. `position_debias_strategy` is one example, which ensures that the order of labels doesn't affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = fastrepl.SimpleEvaluator(\n",
    "    node=fastrepl.LLMClassificationHead(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        context=\"You will receive casual conversation between two people.\",\n",
    "        labels={\n",
    "            \"FUN\": \"at least one of the two people try to be funny and entertain.\",\n",
    "            \"NOT_FUN\": \"given conversation lacks humor or entertainment value.\",\n",
    "        },\n",
    "        position_debias_strategy=\"consensus\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluator\n",
    "\n",
    "Here are some notes about running the evaluator:\n",
    "\n",
    "1. `ThreadPool` is used to make it faster (controlled by the `NUM_THREADS` [environment variable](/getting_started/env.md)).\n",
    "2. Any errors from different LLM providers are properly handled and retried with backoff if necessary.\n",
    "3. Since we passed `num=2` to `run()`, it will execute same evaluation twice, and return two results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da69881235fd4319b59269e904690658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sample', 'result'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fastrepl.LocalRunner(evaluator=evaluator, dataset=ds).run(num=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you like to take a look at the menu, sir...</td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help! Help!\\nWhat's the matter?</td>\n",
       "      <td>[NOT_FUN, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whatever we do, we should do it above board.\\n...</td>\n",
       "      <td>[None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May I see your passport, please?\\nCertainly. H...</td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're thinking about going to America.\\nHave y...</td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do you believe in UFOs?\\nOf course, they are o...</td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What do you think about the equipment in our c...</td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How was your business trip?\\nGreat - they wine...</td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello, Parker. How ’ s everything?\\nCan ’ t co...</td>\n",
       "      <td>[None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Our toner cartridges are already out of ink......</td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample              result\n",
       "0  Would you like to take a look at the menu, sir...  [NOT_FUN, NOT_FUN]\n",
       "1                    Help! Help!\\nWhat's the matter?     [NOT_FUN, None]\n",
       "2  Whatever we do, we should do it above board.\\n...        [None, None]\n",
       "3  May I see your passport, please?\\nCertainly. H...  [NOT_FUN, NOT_FUN]\n",
       "4  We're thinking about going to America.\\nHave y...  [NOT_FUN, NOT_FUN]\n",
       "5  Do you believe in UFOs?\\nOf course, they are o...          [FUN, FUN]\n",
       "6  What do you think about the equipment in our c...  [NOT_FUN, NOT_FUN]\n",
       "7  How was your business trip?\\nGreat - they wine...          [FUN, FUN]\n",
       "8  Hello, Parker. How ’ s everything?\\nCan ’ t co...        [None, None]\n",
       "9  Our toner cartridges are already out of ink......  [NOT_FUN, NOT_FUN]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting point to note is that, due to the `position_debias_strategy=\"consensus\"`, if the order of the labels affects the result, `fastrepl` will return `None`. We'll be returning more meaningful value in the later version of `fastrepl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print([row[0] for row in result[\"result\"]].count(None))\n",
    "print([row[1] for row in result[\"result\"]].count(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got some numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30434782608695654\n",
      "0.27906976744186046\n"
     ]
    }
   ],
   "source": [
    "def metric(result):\n",
    "    f = result.count(\"FUN\")\n",
    "    nf = result.count(\"NOT_FUN\")\n",
    "    return f / (f + nf)\n",
    "\n",
    "\n",
    "print(metric([row[0] for row in result[\"result\"]]))\n",
    "print(metric([row[1] for row in result[\"result\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastrepl` has built-in support for measuring `inter-rater reliability` when `num > 1`. If `num = 2`, it use `Cohen's Kappa`, otherwise, it use `Fleiss' Kappa`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kappa': -0.017678756638306883}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastrepl.Analyzer(result).run(mode=\"kappa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the `metric` we obtained is quite similar, the `Kappa value` indicates that there is poor agreement between the two runs.\n",
    "\n",
    "We will revisit this in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
